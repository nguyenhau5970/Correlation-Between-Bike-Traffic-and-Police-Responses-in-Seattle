{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f8ee71-68b0-413c-b776-f38999b8fe40",
   "metadata": {},
   "source": [
    "# Police Call Data Resampling\n",
    "\n",
    "This notebook takes the cleaned police call data and resamples it. This provides summary data per hour. See the column descriptions below.\n",
    "\n",
    "This notebook could probably be part of the data cleaning notebook, but it's fine to keep it separate.\n",
    "\n",
    "## Setup\n",
    "\n",
    "This script depends on the cleaned data generated by the Data Cleaning notebook. Run that first, which should generate 4 csv files in the `data/cleaned/` directory. 2 of those are the inputs for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec108f23-f299-4bec-bb3c-4b19a1603775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d7228d3-59f9-4d08-bbcc-d1e3e713804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read frames\n",
    "# These csv files should exist if you ran the Data Cleaning notebook.\n",
    "\n",
    "def output_dir(filename = ''):\n",
    "    return os.path.join('data', 'cleaned', filename)\n",
    "\n",
    "fremont_calls_file = output_dir('fremont_calls.csv')\n",
    "greenway_calls_file = output_dir('greenway_calls.csv')\n",
    "\n",
    "# Output files that we'll write to at the very end\n",
    "resampled_fremont_calls_file = output_dir('resampled_fremont_calls.csv')\n",
    "resampled_greenway_calls_file = output_dir('resampled_greenway_calls.csv')\n",
    "\n",
    "# Make sure the files exist\n",
    "if not os.path.exists(fremont_calls_file):\n",
    "    print(f\"{fremont_calls_file} doesn't exist. Run the Data Cleaning notebook first to generate.\")\n",
    "if not os.path.exists(greenway_calls_file):\n",
    "    print(f\"{greenway_calls_file} doesn't exist. Run the Data Cleaning notebook first to generate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6829ad9f-3656-4b20-b365-e36b1ccbfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the call data\n",
    "fc = pd.read_csv('data/cleaned/fremont_calls.csv')\n",
    "gc = pd.read_csv('data/cleaned/greenway_calls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fe998-b09e-404d-baba-f658f37b768e",
   "metadata": {},
   "source": [
    "## Summarizing the Data\n",
    "We want to get hourly totals for the call data. We'll have to summarize because we have a lot of different data per hour. We'll do this by resampling.\n",
    "\n",
    "For numeric values, we'll take the average. For things like call_type, we'll keep each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209d52bc-5772-4c75-844c-100b52657d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates and times\n",
    "def parse_dates_and_times(frame):\n",
    "    # Parse to datetime objects\n",
    "    frame['time_queued'] = pd.to_datetime(frame['time_queued'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "    frame['arrived_time'] = pd.to_datetime(frame['arrived_time'], format=\"%H:%M:%S\")\n",
    "    \n",
    "    # arrived_time only contains a time, so we'll pull the date from time_queued and add it to arrived_time.\n",
    "    # This means that both arrived_time and time_queued both contain full dates and can be more easily compared.\n",
    "    frame['arrived_time'] = frame.apply(\n",
    "        lambda row: row['time_queued'].replace(\n",
    "            hour=row['arrived_time'].hour,\n",
    "            minute=row['arrived_time'].minute,\n",
    "            second=row['arrived_time'].second\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Some time differences cross the date boundary (ie. queued up just before midnight and they arrive after midnight)\n",
    "    # This will check for that and fix the date so it's accurate.\n",
    "    # Basically, if the arrived time of day is less than the queued time, we know it crossed the date boundary.\n",
    "    for index, row in frame.iterrows():\n",
    "        if row['arrived_time'].time() < row['time_queued'].time():\n",
    "            frame.at[index, 'arrived_time'] += pd.DateOffset(days=1)\n",
    "    \n",
    "    frame['arrived_time'] = pd.to_datetime(frame['arrived_time'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Run the above function for both frames\n",
    "parse_dates_and_times(fc)\n",
    "parse_dates_and_times(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f4d86c-1329-479f-ab10-dece68dd7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate arrived_delay\n",
    "fc['arrived_delay'] = (fc['arrived_time'] - fc['time_queued']).dt.total_seconds() / 60 # units in minutes\n",
    "gc['arrived_delay'] = (gc['arrived_time'] - gc['time_queued']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11366ddd-1f76-4a47-912b-660f0402a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll do the actual resampling\n",
    "def resample(frame):\n",
    "    resampled_frame = frame.resample('H', on = 'arrived_time').agg({\n",
    "        # Keep each unique call type\n",
    "        'call_type': lambda call_type: call_type.unique(),\n",
    "        # Keep each unique initial call type\n",
    "        'initial_call_type': lambda initial_call_type: initial_call_type.unique(),\n",
    "        # Keep each unique final call type\n",
    "        'final_call_type': lambda final_call_type: final_call_type.unique(),\n",
    "        # Keep each unique clearance description\n",
    "        'clearance_desc': lambda clearance_desc: clearance_desc.unique(),\n",
    "        # Keep the average priority\n",
    "        'priority': 'mean',\n",
    "        # Keep the average arrived delay that we calculated\n",
    "        'arrived_delay': 'mean',\n",
    "        # this is just the number of rows aggregated, ie. the number of calls in that hour\n",
    "        'cad_num': 'size'\n",
    "    })\n",
    "    \n",
    "    # Rename the columns to be more descriptive\n",
    "    resampled_frame.columns = [\n",
    "        'call_types',\n",
    "        'initial_call_type',\n",
    "        'final_call_types',\n",
    "        'clearance_desc',\n",
    "        'average_priority',\n",
    "        'average_arrived_delay',\n",
    "        'call_count'\n",
    "    ]\n",
    "    resampled_frame.index.name = 'hour'\n",
    "    return resampled_frame\n",
    "\n",
    "resampled_fc = resample(fc)\n",
    "resampled_gc = resample(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7784717a-1d88-4f4c-9e2a-a782b76b786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the resampled data to file\n",
    "resampled_fc.to_csv(resampled_fremont_calls_file)\n",
    "resampled_gc.to_csv(resampled_greenway_calls_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
